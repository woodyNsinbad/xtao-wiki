# 我的任务为什么在排队？

任务排队原因的排查流程

## 调度域quota策略
- 调度域quota包含以下三种类型：
    - Host： 为指定的节点上绑定的指定调度域设置quota
    - AllHosts： 在绑定指定调度域的所有节点上设置相同的quota
    - ClusterTotal： 为集群上绑定指定调度域的节点的资源总和设置quota
    ![poros_domain.png](/pic/queue/poros_domain.png)

ClusterTotal Quota 相比于 AllHosts Quota 的优势是避免资源碎片化，提高了资源利用率。
- 假设我们集群的资源配置是100节点*100CPU，同样是为调度域A设置了20%的CPU  Quota。ClusterTotal模式意味着：调度域A在整个集群的范围内最多可以使用10000*20%=2000个CPU，而AllHosts模式意味着：调度域A在每个节点上最多使用 20个CPU。
    - 假设一任务使用21个CPU，ClusterTotal模式就可以成功调度该任务，而AllHosts则无法调度。

- 另一种情况是，在系统较为繁忙时，AllHosts模式下调度域A在每个节点上可用资源都不多，而恰好有高优先级的任务指定的较多的资源（使用调度域A），那这时即使有低优先级的任务（使用调度域A）使用资源较小，也会因为被高优先级任务挡住导致无法调度。而在ClusterTotal模式下，假设高优先级任务超过了全局Quota，那剩余资源不会被其挡住，低优先级任务还有机会使用.

- AllHosts 模式下，高优先级排队任务会不会挡住使用其他调度域的低优先级任务？
    - 看情况。假设某个节点上目前剩余CPU为10，该节点上有两个调度域A和B，A和B都没有设置节点上的Quota和预留(非全局Quota和预留)，这意味着A和B的都有机会使用这10个CPU。如果此时某个高优先级的任务使用调度域A并且指定CPU为11，此时它即使无法调度也会留下这10个CPU，这样低优先级的使用调度域B的任务就无法使用这10个CPU。

    - 另一种情况是，假设调度域B设置了节点上的预留：10个CPU，那意味着这10个CPU只能给调度域B使用，那么这时候这10个CPU就不会被挡住。这部分在下面的'原因5'以及对应的排除方式中也有提及。实际情况中除非是配置调度域完全的资源隔离，避免调度域之间的资源竞争，否则很难做到不受其他调度域的影响。但这样的话就会影响资源利用率，所以是一个权衡的过程。

    - 这个机制不区分是 ClusterTotal or  AllHosts 模式。简单点来说，某个调度域A在一个节点上能用的资源可以拆分为两类，一类是它自己独享的（设置了节点上的预留），一类是和其他调度域共享的。一旦调度器决定在该节点上 给 调度域A的某个任务 分配资源，那就意味着共享的这部分资源，其他调度域就不能用了。反过来说，如果调度域B决定要把这资源给它的任务，那么调度域A就无法再使用共享的这部分资源，但是仍然能用它自己独享的那部分。

- 若某一列 (CPUS, MEM, GPUS) 不设quota  , 默认 是 1 (100%, 无限制）。


## 原因总结
任务长时间处于排队状态无外乎以下几点原因：

1.原因1：系统当前没有资源可以满足任务的要求。具体原因包括：
    - 系统当前的可用资源不足，可能是运行的任务太多，也可能是资源本身比较稀缺（如GPU）。
    - 其他调度域设置了单节点的资源预留，导致所关注任务使用的调度域的可用资源太少。
    - 所关注任务使用的调度域设置了单节点配额，导致该调度域的可用资源太少。

2.原因2：任务可用的资源尚未分配给Paladin。Achelous的资源管理系统每隔一段时间（通常为几秒钟）就会根据自身的策略选择集群中的部分资源分配给Paladin使用，然后Paladin利用这些资源匹配和调度排队中的任务，这一过程我们称之为一个调度周期。假如Paladin收到的资源集合不满足任务要求，那该任务只能等下个调度周期。Achelous的资源管理系统分配资源的效率很高，通常Paladin在经历几个调度周期之后就会遍历集群中所有的计算资源，所以该原因导致的任务排队不会持续太长时间，通常不超过数分钟。

3.原因3：用户的资源使用达到了Quota上限。Paladin支持为每个用户设置资源使用的上限(默认没有限制），如CPU、Memory等。当某用户的资源使用达到了上限，那他的正在排队的任务就只能等待已运行的任务结束释放资源，或者提高该用户的Quota。hermit/sge quota get命令可以查看用户的Quota统计。

4.原因4：资源被其他任务抢占。该原因与原因1类似，用户可能前一时刻看到还有资源可用，但下一时刻已经被其他任务抢占。

5.原因5：资源被高优先级的任务留置。Paladin调度任务遵循严格的优先级限制。假如某个高优先级任务Task1的配置为: 2 CPU，1G Memory。同时有个低优先级任务Task2配置为：1 CPU，1G Memory。 假设在某个调度周期中节点Node1可用资源为1 CPU, 1G Memory。显然不满足Task1的要求，但是可以满足Task2。但此时Paladin会把Node1的资源留置给Task1，不让Task2使用。这样做的目的是防止高优先级的任务因为资源总被低优先级任务抢占导致始终无法运行。以上为了描述方便没有提及调度域概念，实际上如果Task1和Task2使用的是不同的调度域，彼此之间资源隔离，就不会出现上述现象，即使用调度域A的任务不能留置调度域B的资源。（注：同一优先级中的饥饿任务比非饥饿任务优先级高）

原因6：任务所使用的调度域达到了全局Quota上限。Achelous可以配置某个调度域在整个系统中能使用的资源上限（默认没有限制），如CPU、Memory等。当某个调度域的资源使用达到了上限，那使用该调度域的正在排队的任务就无法运行，只能等待已运行的任务结束释放资源，或者提高该调度域的Quota。


## 查看队列的资源使用情况: hermit scheduler命令

上面提到Paladin每经过几秒钟就会经历一个调度周期（没有任务排队时不进行）。为了方便管理员和用户分析任务阻塞原因，Paladin提供了hermit scheduler命令来展示一个调度周期的详情。hermit scheduler显示的是最近一个调度周期的统计数据，具体内容如下：

1.该调度周期的开始时间（Start time)

2.该调度周期的消耗时间（Elapsed）

3.该调度周期成功匹配的任务数（Matched tasks）

4.参与该调度周期的资源集合，即当时资源管理系统分配给Paladin的资源，包括节点以及节点上的各调度域资源（Offers），示例见下图。
![hermit_1.png](/pic/queue/hermit_1.png)

5.系统中的各调度域的全局Quota限制（Global schedule domain quota），示例见下图。
![hermit_2.png](/pic/queue/hermit_2.png)

6.该调度周期的资源留置情况（Reservation 参见原因5的描述）。解读方式为（以下图为例）：优先级4的非饥饿任务集合留置了节点Cc4Apc上调度域all的资源，该资源是为用户h.g的任务paladin-task.28f10527-3d97-47e4-a582-15c34ceab8d7留置的。示例见下图。
![hermit_3.png](/pic/queue/hermit_3.png)

7.参与各个优先级调度的资源集合(Match with  注：当Paladin为某个优先级留置部分资源时，该资源在下个优先级就不可见。上例中参与优先级3调度的资源集合中看不到Cc4Apc的all资源。）示例见下图。
![hermit_4.png](/pic/queue/hermit_4.png)

8.各个优先级匹配成功的任务集合（Matched）。解读方式为（以下图为例）：优先级4的非饥饿任务集合中，用户h.g的任务paladin-task.d38c96e0-8f4a-4877-86a3-f20fbb3bbe52匹配成功，使用的是Cc8Apc的调度域all的资源。示例见下图。
![hermit_5.png](/pic/queue/hermit_5.png)

## 原因分析

1.原因1导致的任务排队相对容易确认。用户可以通过qhost命令或者登录系统管理界面查看系统的配置和资源使用情况，通常可以直观的判断出来。进一步的，也可以通过hermit scheduler的Offers部分内容确定，观察该部分显示的资源集合能否满足所关注任务的要求。但需要注意的是，hermit scheduler只显示一个调度周期的情况（所显示的资源并非整个系统的可用资源，只是一部分），所以需要连续一段时间不断的通过hermit scheduler获取多个调度周期的数据进行分析，所以通常需要配合一些处理脚本使用。使用该方式可能无法很好的区分原因1和原因2，这时可以让支持工程师介入帮忙确认。

2.针对原因2可以使用hermit scheduler命令进行分析，重点关注Offers部分的显示内容。例如用户已知只有节点Node1的调度域A满足他的任务要求，就可以关注Offers部分显示的资源集合中有没有该资源。hermit scheduler命令显示的是最近一个调度周期的统计情况，而Paladin每隔几秒钟就会经历一个调度周期（hermit config get reviveInterval命令可以显示确切的时间间隔），即hermit scheduler每过几秒钟输出就会发生变化，所以使用hermit scheduler时可能需要配合一些处理脚本进行分析。

3.原因3的判断也比较直接。用户可以使用hermit qstat -i task_id直接查看任务的详情，此时在Message字段会显示任务正等待该用户的资源Quota（或qstat -j short_id中的state_reason字段也显示同样内容），hermit quota get命令可以显示各用户的Quota统计，帮助进一步确定问题原因。

4.原因4的分析手段与原因1相同。进一步的，也可以通过hermit scheduler命令分析，这种情况下可以看到的现象通常是：1.Offers部分显示资源集合可以满足任务的要求；2.Matched部分显示有其他任务匹配成功。

5.原因5的分析过程最为复杂，尤其是当不同的调度域之间存在资源竞争时。比如某个节点Node1上有100个CPU，同时配置有调度域A和B。如果A和B都没有配置预留和配额，那A和B对应的可用CPU都为100。假设此时Paladin决定留置调度域A的资源，实际上留置后B可用的CPU个数为0，因为这100个CPU是A和B共享的，给A留下了那么B就不能使用！但是如果B配置了预留为10个CPU，那Paladin在留置A的资源是只能留下90个CPU，因为剩余10个CPU是给B独占的！综上，复杂的节点调度域配置会大大增加分析难度，所以针对原因5的分析需要对整个机制非常熟悉。不过普通用户可以结合hermit scheduler命令进行初步分析，关注Reservation和Match with部分的显示，观察是否有高优先级的任务留置了某些资源。如果有可疑现象可以让支持工程师介入帮助分析。

6.原因6可以通过hermit scheduler的Global schedule domain quota部分显示确定。以下图为例，alpha调度域当前可用的CPU 最多为42.5，如果一个使用该调度域的任务指定CPU为50，显然该任务无法运行。
![hermit_2.png](/pic/queue/hermit_2.png)

## 建议
1.投递任务前，先查看集群资源使用情况，包括各个节点各类型资源剩余情况（qhost），各调度域在各节点的资源使用情况（通过poros的web界面调度域模块查看资源使用情况）；

2.给自己的任务合理设置资源，如果一开始不确定自己任务需要的合适资源是多少，可以在投递任务时候指定资源自动调节选项，让Achelous来根据任务实际运行情况来调节，自己只需要通过qstat -j [job id]查看调节后的资源就可以确定比较适合该任务的资源值，记录以供后续参考；
